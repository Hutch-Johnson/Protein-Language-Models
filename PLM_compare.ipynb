{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D_bFB1DqSkYn"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# from transformers import AutoModelForCausalLM\n",
        "# from transformers import AutoTokenizer, EsmForMaskedLM\n",
        "# from tokenizers import Tokenizer\n",
        "# import torch.nn.functional as F\n",
        "\n",
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import seaborn as sns\n",
        "# import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_v3C7gmS_rp",
        "outputId": "88d99bff-1a74-4df7-a42c-772fdc3cdca5"
      },
      "outputs": [],
      "source": [
        "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYpfYlX1TEf5"
      },
      "outputs": [],
      "source": [
        "def initialize_esm2(model_name):\n",
        "  # Define tokenizer and model\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "  model = EsmForMaskedLM.from_pretrained(model_name).to(device)\n",
        "  # Evaluate mode\n",
        "  model.eval()\n",
        "  return model, tokenizer\n",
        "\n",
        "def collect_log_prob_esm2(sequence, model, tokenizer):\n",
        "  # Define indices for log-likelihood ratio matrix\n",
        "  amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "  aa_token_ids = [tokenizer.convert_tokens_to_ids(aa) for aa in amino_acids]\n",
        "\n",
        "  # Clean sequence\n",
        "  sequence.replace('\\n','')\n",
        "  sequence.replace(' ','')\n",
        "\n",
        "  # Tokenize sequence for model\n",
        "  inputs = tokenizer(sequence, return_tensors='pt', add_special_tokens=True)\n",
        "\n",
        "  # Output predcitions from model, do not compute gradients\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**inputs)\n",
        "    logits = outputs.logits\n",
        "\n",
        "  input_ids = inputs['input_ids']\n",
        "\n",
        "  # Define tensor of log probabilities for each\n",
        "  # amino acid in each position of the sequence\n",
        "  log_probs = torch.log_softmax(logits, dim=-1)\n",
        "\n",
        "  # Define tensor of reference log probabilities\n",
        "  # the log probabilities for actual amino acid\n",
        "  # in sequence\n",
        "  ref_log_probs = log_probs[0, torch.arange(input_ids.size(1)), input_ids[0]]\n",
        "  # Resize ref_log_probs\n",
        "  ref_log_probs = ref_log_probs.unsqueeze(1)\n",
        "  log_probs = log_probs[0]\n",
        "\n",
        "  # Define the log-likelihood ratio matrix\n",
        "  llr_matrix = log_probs - ref_log_probs\n",
        "  llr_matrix = llr_matrix[1:-1,:]\n",
        "  llr_matrix = llr_matrix[:, aa_token_ids]\n",
        "  log_probs = log_probs[1:-1,:]\n",
        "  log_probs = log_probs[:, aa_token_ids]\n",
        "  ref_log_probs = ref_log_probs[1:-1]\n",
        "\n",
        "  return log_probs, ref_log_probs, llr_matrix\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xo0L0CJa4WA"
      },
      "outputs": [],
      "source": [
        "def llr_heatmap(llr_matrix, positions=None, figsize=(15, 10), cmap='RdBu_r'):\n",
        "\n",
        "  amino_acids = 'ACDEFGHIKLMNPQRSTVWY'\n",
        "\n",
        "  if positions is None:\n",
        "    positions = np.arange(llr_matrix.shape[0])\n",
        "  else:\n",
        "    positions = list(positions)\n",
        "  plt.figure(figsize=figsize)\n",
        "  sns.heatmap(llr_matrix[positions,:].T,\n",
        "              xticklabels=positions,\n",
        "              yticklabels=list(amino_acids),\n",
        "              cmap=cmap,\n",
        "              center=0,\n",
        "              cbar_kws={'label': 'LLR'})\n",
        "  plt.xlabel('Position in CRX')\n",
        "  plt.ylabel('Amino Acid')\n",
        "  plt.title('Log-Likelihood Ratio Matrix')\n",
        "  plt.tight_layout()\n",
        "\n",
        "  return plt\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2d1R8o_n3Ff"
      },
      "outputs": [],
      "source": [
        "def seq_matrix_dict(sequence_list, model, tokenizer):\n",
        "\n",
        "  seq_dict = dict()\n",
        "\n",
        "  n = len(sequence_list)\n",
        "\n",
        "  for i in range(n):\n",
        "    sequence = sequence_list[i]\n",
        "    lp, rlp, llr = collect_log_prob_esm2(sequence, model, tokenizer)\n",
        "\n",
        "    seq_dict[i] = {'log_probs': lp, 'ref_log_probs': rlp, 'llr_matrix': llr}\n",
        "\n",
        "  return seq_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMJ2TEJ6XYAH"
      },
      "outputs": [],
      "source": [
        "# model_name = \"facebook/esm2_t33_650M_UR50D\"\n",
        "# crx_sequence = \"MMAYMNPGPHYSVNALALSGPSVDLMHQAVPYPSAPRKQRRERTTFTRSQLEELEALFAKTQYPDVYAREEVALKINLPESRVQVWFKNRRAKCRQQRQQQKQQQQPPGGQAKARPAKRKAGTSPRPSTDVCPDPLGISDSYSPPLPGPSGSPTTAVATVSIWSPASESPLPEAQRAGLVASGPSLTSAPYAMTYAPASAFCSSPSAYGSPSSYFSGLDPYLSPMVPQLGGPALSPLSGPSVGPSLAQSPTSLSGQSYGAYSPVDSLEFKDPTGTWKFTYNPMDPLDYKDQSAWKFQIL\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZHPCjY2yXv-K"
      },
      "outputs": [],
      "source": [
        "# model, tokenizer = initialize_esm2(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "uzi_sXVppu6u",
        "outputId": "c44bf141-2079-4e89-edd0-365bc260a126"
      },
      "outputs": [],
      "source": [
        "# seq_matrix_dict([crx_sequence], model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mXe9ilwUZWve"
      },
      "outputs": [],
      "source": [
        "# crx_lp, crx_rlp, crx_llr = collect_log_prob_esm2(crx_sequence, model, tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "Yd3FLpPUiAY-",
        "outputId": "01e8a83a-1e28-49c2-d9a9-0c21a3b909cd"
      },
      "outputs": [],
      "source": [
        "# llr_heatmap(crx_llr,positions=range(20,50))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
